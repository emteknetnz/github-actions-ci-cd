# https://docs.github.com/en/actions/learn-github-actions/workflow-syntax-for-github-actions
# https://docs.github.com/en/actions/learn-github-actions/contexts#context-availability
# https://docs.github.com/en/actions/learn-github-actions/reusing-workflows

# TODO - functionality
# - [ ] job to validate/sanitize inputs

# TODO - readme
# - [ ] how to do cron on modules

# TODO - dynmaic matrix
# - [ ] matrix entry for graphql3 vs 4 for behat
# - [ ] PDO matrix entry
# - [ ] PGSQL matrix entry
# - [ ] --prefer-lowest

# TODO - optimisations
# - [ ] npm cache (similar to composer cache)
# - [ ] tidy-up of heredocs / temporary inline php files
# - [ ] behat green/red colours in output, also phpunit?
# - [ ] consider getting rid of apache and use serve.php for behat since it'll run the job faster and it simplies this file (though behat will always be slow)
# - [ ] consider splitting code into multiple yml files / repos

name: ci

on:
  workflow_call:
    inputs:
      # extra jobs must be multi-line string, as there's no support for type: array for inputs
      extra_jobs:
        type: string
        required: false
        default: ''
      composer_require_extra:
        type: string
        required: false
        default: ''
      # simple matrix will only run a single php 7.4 mysql 5.7 job instead of a full matrix
      simple_matrix:
        type: boolean
        default: false
      run_endtoend:
        type: boolean
        default: true
      run_phpcoverage:
        type: boolean
        # modules on silverstripe account will ignore this and always run codecov
        default: false
      run_phplinting:
        type: boolean
        default: true
      run_phpunit:
        type: boolean
        default: true
      run_js:
        type: boolean
        default: true

jobs:
  context:
    name: Context
    runs-on: ubuntu-latest
    steps:
      - name: Context
        run: |
          # https://docs.github.com/en/actions/learn-github-actions/contexts#context-availability
          echo "github.base_ref: ${{ github.base_ref }}"
          echo "github.event_name: ${{ github.event_name }}"
          echo "github.head_ref: ${{ github.head_ref }}"
          echo "github.ref: ${{ github.ref }}"
          echo "github.ref_name: ${{ github.ref_name }}"
          echo "github.ref_type: ${{ github.ref_type }}"
          echo "github.repository: ${{ github.repository }}"
          echo "github.sha: ${{ github.sha }}"
          echo "job.status: ${{ job.status }}"
          # https://docs.github.com/en/actions/learn-github-actions/events-that-trigger-workflows
          echo "github.event.issue.pull_request: ${{ github.event.issue.pull_request }}"
          echo "github.event.issue.number: ${{ github.event.issue.number }}"
          echo "github.event.repository.name: ${{ github.event.repository.name }}"

  # used to generate a dynamic jobs matrix
  genmatrix:
    name: Generate matrix
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.generate-matrix.outputs.matrix }}
    steps:
      - name: Generate matrix
        id: generate-matrix
        uses: emteknetnz/gha-generate-matrix@main
        with:
          extra_jobs: ${{ inputs.extra_jobs }}
          simple_matrix: ${{ inputs.simple_matrix }}
          run_endtoend: ${{ inputs.run_endtoend }}
          run_phpcoverage: ${{ inputs.run_phpcoverage }}
          run_phplinting: ${{ inputs.run_phplinting }}
          run_phpunit: ${{ inputs.run_phpunit }}
          run_js: ${{ inputs.run_js }}

  tests:
    runs-on: ubuntu-latest

    services:
      mysql:
        image: mysql:5.7
        env:
          MYSQL_HOST: 127.0.0.1
          MYSQL_ROOT_PASSWORD: root
          MYSQL_DATABASE: SS_mysite
        ports:
          - 3306:3306
        options: --health-cmd="mysqladmin ping" --health-interval=10s --health-timeout=5s --health-retries=3

    needs: genmatrix

    strategy:
      # set fail-fast to false prevent one job from cancelling other jobs
      fail-fast: false
      matrix: ${{fromJson(needs.genmatrix.outputs.matrix)}}

    env:
      artifacts_name: php${{ matrix.php }}_${{ matrix.phpunit && 'phpunit - ' && matrix.phpunit_suite || '' }}${{ matrix.endtoend && 'endtoend' || '' }}${{ matrix.js && 'js' || '' }}${{ matrix.phpcoverage && 'phpcoverage' || '' }}${{ matrix.phplinting && 'phplinting' || '' }}

    name: PHP ${{ matrix.php }} ${{ matrix.phpunit && ' - phpunit - ' || '' }}${{ matrix.phpunit && matrix.phpunit_suite || '' }}${{ matrix.endtoend && ' - endtoend - ' || '' }}${{ matrix.endtoend && matrix.endtoend_suite || '' }}${{ matrix.js && ' - js' || '' }}${{ matrix.phpcoverage && ' - phpcoverage' || '' }}${{ matrix.phplinting && ' - phplinting' || '' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Install PHP
        uses: shivammathur/setup-php@v2
        with:
          php-version: ${{ matrix.php }}
          extensions: curl, dom, gd, intl, json, ldap, mbstring, mysql, tidy, xdebug, zip
          tools: composer:v2
          coverage: xdebug
        # While this should be the correct way to allow forks in composer.json repositories
        # in practice there are still many sporadic "Could not authenticate against github.com" errors
        # there's 1,000 requests per hour limit when using this token, likely it get exceeded
        # fairly easily when using a fork with multiple jobs in a matrix
        #env:
        #  COMPOSER_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Configure PHP
        run: |
          # Set memory limit and disable xdebug if not running phpcoverage
          if [ ! $(which php) ]; then echo "PHP not installed, skipping" && exit 0; fi
          sudo sh -c "echo 'memory_limit = 8196M' >> /etc/php/${{ matrix.php }}/cli/php.ini"
          if [ -f /etc/php/${{ matrix.php }}/apache2/php.ini ]; then
            sudo sh -c "echo 'memory_limit = 8196M' >> /etc/php/${{ matrix.php }}/apache2/php.ini"
          fi
          # Disable xdebug which greatly slow down unit testing
          # Note: omitting xdebug from shivammathur/setup-php still results in xdebug being installed and enabled
          if ! [ ${{ matrix.phpcoverage }} ]; then
            sudo sh -c "echo ';zend_extension=xdebug.so' > /etc/php/${{ matrix.php }}/mods-available/xdebug.ini"
          fi
          echo "PHP has been configured"

      - name: Apt install additional requirements 
        run: |
          # apt install extra requirements as required
          if [ ${{ matrix.endtoend }} ]; then
            sudo apt install -y software-properties-common
            sudo add-apt-repository -y ppa:ondrej/php
            sudo add-apt-repository -y ppa:ondrej/apache2
            sudo apt update
            sudo apt install -y libapache2-mod-php${{ matrix.php }}
            # ubuntu-latest will install a current version of google-chrome-stable (currently 95)
            # so there's no need to install chromium like we used to on travis-shared
          fi
          if [[ ${{ github.repository }} =~ /(spellcheck|recipe-authoring-tools)$ ]] || [ ${{ matrix.phpunit_suite }} == recipe-authoring-tools ]; then
            sudo apt install -y hunspell libhunspell-dev hunspell-en-us
          fi

      - name: Configure apache - endtoend test
        if: ${{ matrix.endtoend }}
        run: |
          # apache2 is installed and running by default in ubuntu
          # update dir.conf to use index.php as the primary index doc
          cat << EOF > __dir.conf
          <IfModule mod_dir.c>
              DirectoryIndex index.php index.html index.cgi index.pl index.xhtml index.htm
          </IfModule>
          EOF
          # TODO: sudo cat and get rid of cp?
          sudo cp __dir.conf /etc/apache2/mods-enabled/dir.conf
          rm __dir.conf
          # this script will create a 000-default.conf file with the pwd as the DocumentRoot
          cat << EOF > __000-default.conf
          <VirtualHost *:80>
            ServerAdmin webmaster@localhost
            DocumentRoot PWD
            <Directory PWD>
              AllowOverride All
              Require all granted
            </Directory>
            ErrorLog ${APACHE_LOG_DIR}/error.log
            CustomLog ${APACHE_LOG_DIR}/access.log combined
          </VirtualHost>
          EOF
          # TODO: this could be replace with using bash a variable pwd/cwd straight into the inline php
          cat << EOF > __apache2.php
          <?php
          \$pwd = rtrim(trim(shell_exec('pwd')), '/');
          \$s = file_get_contents('__000-default.conf');
          \$s = str_replace('PWD', \$pwd, \$s);
          file_put_contents('__000-default.conf', \$s);
          EOF
          php __apache2.php
          sudo cp __000-default.conf /etc/apache2/sites-enabled/000-default.conf
          rm __000-default.conf
          sudo a2enmod rewrite
          # run apache as 'runner:docker' instead of 'www-data:www-data'
          sudo sh -c "echo 'export APACHE_RUN_USER=runner' >> /etc/apache2/envvars"
          sudo sh -c "echo 'export APACHE_RUN_GROUP=docker' >> /etc/apache2/envvars"
          sudo systemctl restart apache2
          echo "Apache has been configured"

      # This is shared between runs, not just jobs. It means the first time the repo runs the job it'll
      # need to download requirements for the first time, after that it will be plenty quick
      # https://docs.github.com/en/actions/advanced-guides/caching-dependencies-to-speed-up-workflows
      - name: Enable shared composer cache
        uses: actions/cache@v2
        with:
          path: ~/.cache/composer
          key: shared-composer-cache

      - name: Composer
        env:
          COMPOSER_REQUIRE_EXTRA: ${{ inputs.composer_require_extra }}
        run: |
          # Update composer.json and install dependencies
          # github.base_ref is only available on pull-requests and is the target branch
          # TODO: ^ confirm if this is prefixed with refs/heads/
          # github.ref_name is used for regular branch builds such as crons - it is NOT prefixed with refs/heads/
          # https://docs.github.com/en/actions/learn-github-actions/contexts#context-availability
          BRANCH=$(php -r "echo preg_replace('#^pulls/([0-9\.]+)/.+\$#', '\$1', '${{ github.base_ref }}'?:'${{ github.ref_name }}');")
          if [[ "$BRANCH" =~ ^[1-9]$ ]] || [[ "$BRANCH" =~ ^[1-9]\.[0-9]+$ ]]; then export COMPOSER_ROOT_VERSION="${BRANCH}.x-dev"; elif [[ "$BRANCH" =~ ^[1-9]\.[0-9]+\.[0-9]+ ]]; then export COMPOSER_ROOT_VERSION="${BRANCH}"; else export COMPOSER_ROOT_VERSION="dev-${BRANCH}"; fi
          echo "BRANCH is $BRANCH"
          echo "COMPOSER_ROOT_VERSION is $COMPOSER_ROOT_VERSION"

          # Detect if using phpunit9
          # If so, then ensure sminnee phpunit5 modules do not get installed
          PHPUNIT9=$(php -r '$rd=json_decode(file_get_contents("composer.json"))->{"require-dev"};$pu=$rd->{"phpunit/phpunit"}??"";$rt=$rd->{"silverstripe/recipe-testing"}??"";echo ($pu=="^9"||$pu=="^9.5"||$rt=="^2")?1:0;')
          echo "PHPUNIT9 is $PHPUNIT9"
          if [ $PHPUNIT9 == 1 ]; then
            php -r "\$j=json_decode(file_get_contents('composer.json'));\$j->replace=json_decode('{\"sminnee/phpunit\":\"*\",\"sminnee/phpunit-mock-objects\":\"*\"}');file_put_contents('composer.json', json_encode(\$j, JSON_PRETTY_PRINT + JSON_UNESCAPED_SLASHES));"
          fi

          # Require silverstripe/installer for non-recipe and all but a few modules
          if ! [[ ${{ github.repository }} =~ /(recipe-|silverstripe-config|silverstripe-installer|vendor-plugin) ]]; then
            INSTALLER_VERSION=4.x-dev
            if [[ "$COMPOSER_ROOT_VERSION" =~ "x-dev" ]]; then INSTALLER_VERSION=$(php -r "echo preg_replace('/^[0-9]+/', '4', '$COMPOSER_ROOT_VERSION');"); fi
            echo "INSTALLER_VERSION is $INSTALLER_VERSION"
            composer require silverstripe/installer:$INSTALLER_VERSION --no-update
          fi
          
          # Required for assets unit tests as well as recipes that run assets unit tests
          # Should technically be defined as composer_require_extra on individual modules, though easier just doing here
          composer require mikey179/vfsstream:^1 --dev --no-update

          # require graphql 3 most of the time
          # require graphql 4 for endtoend tests on php 8.0
          if ! [[ ${{ github.repository }} =~ /graphql$ ]]; then
            if [ ${{ matrix.endtoend }} ] && [ "${{ matrix.php }}" == "8.0" ]; then
              composer require silverstripe/graphql:^4 --no-update
            else
              composer require silverstripe/graphql:^3 --no-update
            fi
          fi

          if [ ${{ matrix.endtoend }} ]; then
            composer require silverstripe/recipe-testing:^2 --dev --no-update
          fi
          if [ ${{ matrix.phplinting }} ]; then
            composer require silverstripe/cow:dev-master --dev --no-update
          fi
          if [ "$COMPOSER_REQUIRE_EXTRA" != "" ]; then
            # TODO: test that requiring multiple modules seperated with a space here works
            composer require $COMPOSER_REQUIRE_EXTRA --no-update
          fi
          cat composer.json

          # Installing using --prefer-source for recipes + some modules that run other unit-tests in other modules
          composer update --prefer-source --no-interaction --no-progress ${{ matrix.composer_arg }}

      - name: Final preparation
        run: |
          # Add .env file and create artifacts directory
          cat << EOF > .env
          SS_ENVIRONMENT_TYPE="dev"
          SS_DATABASE_CLASS="MySQLDatabase"
          SS_DATABASE_SERVER="127.0.0.1"
          SS_DATABASE_USERNAME="root"
          SS_DATABASE_PASSWORD="root"
          SS_DATABASE_NAME="SS_mysite"
          SS_DEFAULT_ADMIN_USERNAME="admin"
          SS_DEFAULT_ADMIN_PASSWORD="password"
          SS_TRUSTED_PROXY_IPS="*"
          SS_MFA_SECRET_KEY="1234567894175b99966561e1efe237e4"
          SS_BASE_URL="http://localhost"
          EOF

          # Artifacts directory must be created after composer install as it would remove the artifacts directory
          mkdir artifacts
          
          # run dev/build flush to help debug any issues (though it's not strictly required here)
          # travis-shared has no reference to sake, so it should be safe to omit dev/build flush=1
          # normal module
          if [ -f vendor/bin/sake ]; then vendor/bin/sake dev/build flush=1; fi
          # framework module
          if [ -f sake ]; then sake dev/build flush=1; fi
          
          # Delete the silverstripe-cache dir - it will automatically recreate when needed
          # There were issues with a unit test getting the following issue
          # Identifier name 'SilverStripe_CampaignAdmin_Tests_AddToCampaignValidatorTest_TestObject' is too long
          # Likely because the /tmp/silverstripe-cache-php7.4.xyz... dir being out of sync with TestOnly objects
          rm -rf $(find /tmp -maxdepth 1 | grep silverstripe-cache)

      - name: Debug
        run: |
          echo "matrix.phpunit: ${{ matrix.phpunit }}"

      - name: Run tests
        uses: emteknetnz/gha-run-tests@main
        with:
          phpunit: ${{ matrix.phpunit }}
          phpunit_suite: ${{ matrix.phpunit_suite }}
          endtoend: ${{ matrix.endtoend }}
          endtoend_suite: ${{ matrix.endtoend_suite }}
          js: ${{ matrix.js }}
          phplinting: ${{ matrix.phplinting }}
          phpcoverage: ${{ matrix.phpcoverage }}

      # All tests are contained in a single giant step, as opposed to many smaller steps with an 'if' yml condition,
      # so that the there are a bunch of irrelevant skipped steps e.g. skipping "Test endtoend" on a phpunit run
      # - name: Run tests
      #   run: |
      #     # Run the tests for the matrix entry

      #     if [ ${{ matrix.phpunit }} ]; then
      #       if [ "${{ matrix.phpunit_suite }}" == "all" ]; then
      #         vendor/bin/phpunit --verbose --colors=always
      #       else
      #         vendor/bin/phpunit --verbose --colors=always --testsuite ${{ matrix.phpunit_suite }}
      #       fi
      #       echo "Passed"

      #     elif [ ${{ matrix.endtoend }} ]; then
      #       # Run behat tests
      #       if [ ! -f behat.yml ]; then echo "behat.yml missing" && exit 1; fi
      #       # this script will update behat.yml to work with headless chrome
      #       cat << EOF > __behat_headless.yml
      #     default:
      #       suites: []
      #       extensions:
      #         SilverStripe\BehatExtension\MinkExtension:
      #           default_session: facebook_web_driver
      #           javascript_session: facebook_web_driver
      #           facebook_web_driver:
      #             browser: chrome
      #             wd_host: "http://127.0.0.1:9515"
      #             capabilities:
      #               extra_capabilities:
      #                 chromeOptions:
      #                   args:
      #                     # no sandbox is required to run chromium inside a container https://stackoverflow.com/a/59154049
      #                     - "--no-sandbox"
      #                     # run headless within container - removes the need for xvfb
      #                     - "--headless"
      #                     # disable gpu is often mentioned as fix after headless chrome suddenly breaks after an update
      #                     # leaving it in just in case to prevent hard to diagnose errors later
      #                     - "--disable-gpu"
      #           browser_name: chrome
      #         SilverStripe\BehatExtension\Extension:
      #           screenshot_path: '%paths.base%/artifacts/screenshots'
      #     EOF
      #       cat << EOF > __behat.php
      #       <?php
      #       // use __behat_headless.yml as the main behat.yml file,
      #       // though use 'suites' from the module behat.yml
      #       \$a = trim(file_get_contents('__behat_headless.yml'));
      #       \$b = file_get_contents('behat.yml');
      #       preg_match("#(?s)  suites:(.+?)\n  [a-z]#", \$b, \$m);
      #       if (!\$m) {
      #           preg_match("#(?s)  suites: (.+?)\$#", \$b, \$m);
      #       }
      #       if (!\$m) {
      #           echo "Could not match suites in behat.yml, cannot run behat\n\n";
      #           die;
      #       }
      #       \$c = str_replace('suites: []', 'suites: ' . \$m[1], \$a);
      #       file_put_contents('behat.yml', \$c);
      #     EOF
      #       php __behat.php
      #       rm __behat.php
      #       rm __behat_headless.yml
      #       nohup sh -c "chromedriver" > /dev/null 2>&1 &
      #       vendor/bin/behat --colors --strict
      #       echo "Passed"

      #     elif [ ${{ matrix.js }} ]; then
      #       # Run yarn test etc
      #       if [ ! -f package.json ]; then echo "package.json missing" && exit 1; fi
      #       wget https://raw.githubusercontent.com/nvm-sh/nvm/v0.35.3/install.sh
      #       php -r "if (hash_file('sha384', 'install.sh') === 'dd4b116a7452fc3bb8c0e410ceac27e19b0ba0f900fe2f91818a95c12e92130fdfb8170fec170b9fb006d316f6386f2b') { echo 'Installer verified'; } else { echo 'Installer corrupt'; unlink('install.sh'); } echo PHP_EOL;"
      #       if [ ! -f install.sh ]; then echo "Cannot install nvm" && exit 1; fi
      #       . install.sh
      #       rm install.sh
      #       export NVM_DIR="$HOME/.nvm"
      #       # this loads nvm into the current terminal
      #       [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"
      #       if [ ! -f .nvmrc ]; then echo "Missing .nvmrc" && exit 1; fi
      #       nvm install
      #       nvm use
      #       rm -rf client/dist
      #       npm install -g yarn
      #       yarn install --network-concurrency 1
      #       if [ -d vendor/silverstripe/admin ]; then
      #         cd vendor/silverstripe/admin
      #         yarn install --network-concurrency 1
      #         cd ../../..
      #       fi
      #       yarn run build
      #       git diff-files --quiet -w --relative=client
      #       git diff --name-status --relative=client
      #       yarn run test
      #       yarn run lint
      #       echo "Passed"

      #     elif [ ${{ matrix.phplinting }} ]; then
      #       # Run phpcs
      #       if [ ! -f phpcs.xml.dist ]; then echo "Missing phpcs.xml.dist" && exit 1; fi
      #       vendor/bin/phpcs
      #       # phpstan is optional
      #       if [ -f phpstan.neon.dist ]; then
      #         vendor/bin/phpstan analyse
      #       fi
      #       # cow validation is also done here due to it being a tiny piece of work not meriting its own step
      #       if [ -f .cow.json ]; then
      #         vendor/bin/cow schema:validate
      #       fi
      #       echo "Passed"

      #     elif [ ${{ matrix.phpcoverage }} ]; then
      #       curl https://keybase.io/codecovsecurity/pgp_keys.asc | gpg --import
      #       curl -Os https://uploader.codecov.io/latest/codecov-linux
      #       curl -Os https://uploader.codecov.io/latest/codecov-linux.SHA256SUM
      #       curl -Os https://uploader.codecov.io/latest/codecov-linux.SHA256SUM.sig
      #       gpg --verify codecov-linux.SHA256SUM.sig codecov-linux.SHA256SUM
      #       shasum -a 256 -c codecov-linux.SHA256SUM
      #       chmod +x codecov-linux
      #       phpdbg -qrr vendor/bin/phpunit --coverage-clover=coverage.xml
      #       ./codecov-linux -f coverage.xml;
      #       echo "coverage.xml generated and uploaded to codecov"
      #     fi

      - name: Copy artifacts
        if: always()
        run: |
          # Copy selected files to the artifacts dir
          if [ -f composer.json ]; then cp composer.json artifacts; fi
          if [ -f composer.lock ]; then cp composer.lock artifacts; fi
          if [ ${{ matrix.endtoend }} ] && [ -f behat.yml ]; then cp behat.yml artifacts; fi

      - name: Upload artifacts
        uses: actions/upload-artifact@v2
        if: always()
        with:
          name: ${{ env.artifacts_name }}
          path: artifacts
